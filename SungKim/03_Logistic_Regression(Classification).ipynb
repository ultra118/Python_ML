{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regerssion(Classification)\n",
    "\n",
    "\n",
    "- Binary Classification\n",
    "    - 0 or 1\n",
    "- Linear Regression으로 Classification을 할 떄의 문제\n",
    "    - 1. 튀는 데이터가 input으로 들어가면 분류하는 선이 그 데이터에 영향을 많이 받아 기존의 1에 해당하는 데이터가 0으로 바뀌는 상황발생\n",
    "    - 2. Hypothesis가 0 or 1 의 값이 안나옴\n",
    "        - H(x) = Wx + b\n",
    "        \n",
    "### Logistic Hypothesis\n",
    "- g(z) = 0~1 사이의 값을 만들어주는 함수\n",
    "    - sigmoid : 양수로 커지면 1에 가까워지고  음수로 커지면 0에 가까워 짐\n",
    "        - logistic function이라고도 부름\n",
    "        \n",
    "![image](https://user-images.githubusercontent.com/28910538/53931220-b1676380-40d7-11e9-9304-2b1ef2038ecd.png)\n",
    "\n",
    "\n",
    "###  Cost function\n",
    "- 기존의 cost(W,b)에 넣으면\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28910538/53931005-c8f21c80-40d6-11e9-88d9-21ea1156f103.png)\n",
    "- 구불구불한 그래프가 나옴 \n",
    "    - sigmoid는 linear한 선이 아니기때문\n",
    "    - local minima에 걸릴 수 있음\n",
    "- 그렇기 때문에 Hypothesis에 맞는 cost function을 바꿔줘야 함\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28910538/53931098-1ec6c480-40d7-11e9-81d1-7f17850ac5ef.png)\n",
    "\n",
    "- y가 1일때 H(x)가 1로 맞추면 cost = 0 , H(x)가 0이나와서 틀리면 무한대에 가까운 값\n",
    "- y가 0일때 H(x)가 0으로 맞추면 cost = 0, H(x)가 1이나와서 틀리면 무한대에 가까운 값\n",
    "\n",
    "![image](https://user-images.githubusercontent.com/28910538/53932104-6e0ef400-40db-11e9-805f-a9022c6b9451.png)\n",
    "- y가 1이면 = -log(H(x))\n",
    "- y가 0이면 = -log(1-H(x))\n",
    "\n",
    "### Minimize cost - Gradient descent algorithm\n",
    "![image](https://user-images.githubusercontent.com/28910538/53932140-a31b4680-40db-11e9-8fe6-4493e8451900.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 4.014467716217041\n",
      "cost : 0.47142186760902405\n",
      "cost : 0.3529631197452545\n",
      "cost : 0.31661227345466614\n",
      "accuracy : 0.8333333134651184\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[1, 2],\n",
    "          [2, 3],\n",
    "          [3, 1],\n",
    "          [4, 3],\n",
    "          [5, 3],\n",
    "          [6, 2]]\n",
    "y_data = [[0],\n",
    "          [0],\n",
    "          [0],\n",
    "          [1],\n",
    "          [1],\n",
    "          [1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "#hypothesis = 1./(1.+tf.exp(tf.matmul(X,W)))\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W)+b)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(\"cost : {}\".format(cost_val))\n",
    "\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)    \n",
    "correct = tf.equal(predicted, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data shape : (759, 8), y_data shape : (759, 1)\n",
      "cost val : 0.7441728115081787\n",
      "cost val : 0.6767153739929199\n",
      "cost val : 0.6384781002998352\n",
      "cost val : 0.6082719564437866\n",
      "cost val : 0.5843397974967957\n",
      "cost val : 0.5653481483459473\n",
      "accuracy : 0.7101449370384216\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "data_csv = pd.read_csv(\"./data/data-03-diabetes.csv\", sep=\",\", header=None)\n",
    "x_data = data_csv.values[:,:8]\n",
    "y_data = data_csv.values[:,-1]\n",
    "y_data = y_data.reshape([-1,1])\n",
    "print(\"x_data shape : {}, y_data shape : {}\".format(x_data.shape, y_data.shape))\n",
    "\n",
    "X = tf.placeholder(shape = [None, 8], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8,1]), dtype = tf.float32)\n",
    "b = tf.Variable(tf.random_normal([1]), dtype = tf.float32)\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X,W) + b)\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "sess =tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train, cost], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(\"cost val : {}\".format(cost_val))\n",
    "predicted = tf.cast(hypothesis > 0.5, tf.float32)\n",
    "correct = tf.equal(predicted, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "\n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
