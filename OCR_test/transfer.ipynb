{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname_img = 'train-images_mnist.idx3-ubyte'\n",
    "fashion_fname_img = 'train-images_fashion-idx3-ubyte'\n",
    "fname_lbl = 'train-labels_mnist.idx1-ubyte'\n",
    "fashion_fname_lbl = 'train-labels_fashion-idx1-ubyte'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fname_lbl, 'rb') as flbl:\n",
    "    magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "    lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open(fname_img, 'rb') as fimg:\n",
    "    magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def show(image):\n",
    "    \"\"\"\n",
    "    Render a given numpy.uint8 2D array of pixel data.\n",
    "    \"\"\"\n",
    "    image = np.reshape(image , [28,28])\n",
    "    from matplotlib import pyplot\n",
    "    import matplotlib as mpl\n",
    "    fig = pyplot.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
    "    imgplot.set_interpolation('nearest')\n",
    "    ax.xaxis.set_ticks_position('top')\n",
    "    ax.yaxis.set_ticks_position('left')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import  Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_y  = keras.utils.np_utils.to_categorical(lbl ,  10  )\n",
    "train_x = np.asarray(img)\n",
    "train_y = np.asarray(train_y) \n",
    "print train_y.shape\n",
    "print train_x.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = np.reshape(train_x , [60000,28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.reset_states() \n",
    "\n",
    " \n",
    "model.add(Convolution2D(64, 3, 3,  input_shape = train_x[0].shape , name = \"con1\") ) \n",
    "model.add(Activation('relu' , name = \"act1\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool1\") )\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, name = \"con2\"))\n",
    "model.add(Activation('relu', name = \"act2\" ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool2\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "#model.fit( train_x , train_y  , batch_size= 250 ,   nb_epoch = 5 ,  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 con1\n",
      "1 act1\n",
      "2 pool1\n",
      "3 con2\n",
      "4 act2\n",
      "5 pool2\n",
      "6 flatten_2\n",
      "7 dense_2\n",
      "8 activation_2\n"
     ]
    }
   ],
   "source": [
    "for ii, val  in enumerate(model.layers ): \n",
    "    print ii , val.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"mnist_original_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "model.save_weights(\"mnist_original_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "get_layer_output = K.function([model.layers[0].input, K.learning_phase()], [model.layers[5].output])\n",
    "get_layer_output_early = K.function([model.layers[0].input, K.learning_phase()], [model.layers[2].output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(fashion_fname_lbl , 'rb') as flbl:\n",
    "    magic, num = struct.unpack(\">II\", flbl.read(8))\n",
    "    fashion_lbl = np.fromfile(flbl, dtype=np.int8)\n",
    "\n",
    "with open(fashion_fname_img, 'rb') as fimg:\n",
    "    magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
    "    fashion_img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
    "\n",
    "yy = fashion_lbl\n",
    "inds = yy.argsort()\n",
    "\n",
    "fashion_img= fashion_img[inds]\n",
    "fashion_lbl=  fashion_lbl[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h1>NOW RUNNING EXPTS ON REDUCED FASHION MNIST DATA!</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h1>===============================================</h1>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML('<h1>NOW RUNNING EXPTS ON REDUCED FASHION MNIST DATA!</h1>'))\n",
    "display(HTML('<h1>===============================================</h1>'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fashion_x = []\n",
    "train_fashion_y = []\n",
    "\n",
    "test_fashion_x = []\n",
    "test_fashion_y = []\n",
    "\n",
    "take_number_of_training_images = 5000\n",
    "for i in range(0,len(fashion_lbl),6000 ): \n",
    "    train_fashion_x.extend(fashion_img[i:i+take_number_of_training_images])\n",
    "    train_fashion_y.extend(fashion_lbl[i:i+take_number_of_training_images])\n",
    "    \n",
    "    test_fashion_x.extend(fashion_img[i+take_number_of_training_images:i+6000])\n",
    "    test_fashion_y.extend(fashion_lbl[i+take_number_of_training_images:i+6000])\n",
    "\n",
    "train_fashion_x = np.asarray(train_fashion_x)\n",
    "train_fashion_x = np.reshape(train_fashion_x , [len(train_fashion_x),28,28,1])\n",
    "train_fashion_y  = np.asarray(train_fashion_y)\n",
    "\n",
    "test_fashion_y  = np.asarray(test_fashion_y)\n",
    "test_fashion_x = np.asarray(test_fashion_x)\n",
    "test_fashion_x = np.reshape(test_fashion_x , [len(test_fashion_x),28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "50000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print len(train_fashion_x)\n",
    "print len(train_fashion_y)\n",
    "print len(test_fashion_x)\n",
    "print len(test_fashion_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "z = zip(test_fashion_x, test_fashion_y)\n",
    "random.shuffle(z)\n",
    "test_fashion_x, test_fashion_y = zip(*z)\n",
    "test_fashion_x = np.asarray(test_fashion_x)\n",
    "test_fashion_y = np.asarray(test_fashion_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feats_fashion_mnist_training( inputs ): \n",
    "     \n",
    "    layer_out = get_layer_output([inputs, 0 ])[0]  \n",
    "    return layer_out.reshape([len(layer_out), layer_out[0].shape[0]*layer_out[0].shape[1]*layer_out[0].shape[2]  ] )\n",
    "def get_early_feats_fashion_mnist_training( inputs ): \n",
    "    layer_out = get_layer_output_early([inputs, 0 ])[0] \n",
    "    return layer_out.reshape([len(layer_out), layer_out[0].shape[0]*layer_out[0].shape[1]*layer_out[0].shape[2]  ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_linear_model( train_x , train_y , test_x , test_y ) : \n",
    "    train_x = train_x.reshape( len(train_x), train_x[0].shape[0]*train_x[0].shape[0] )\n",
    "    test_x = test_x.reshape( len(test_x), test_x[0].shape[0]*test_x[0].shape[0]  )\n",
    "    \n",
    "    dict = { }\n",
    "     \n",
    "    clf = linear_model.SGDClassifier()\n",
    "    clf.fit(train_x, train_y  )\n",
    "    print \"model fitted\"\n",
    "    preds = clf.predict( test_x )\n",
    "    acc =  accuracy_score(test_y , preds )\n",
    "    dict[\"linear_SVM\"] = acc\n",
    "   \n",
    "    return dict \n",
    "     \n",
    "    clf = LinearSVC()\n",
    "    clf.fit(train_x, train_y  )\n",
    "    print \"model fitted\"\n",
    "    preds = clf.predict( test_x )\n",
    "    acc =  accuracy_score(test_y , preds )\n",
    "    dict[\"linear_SVC\"] = acc\n",
    "\n",
    " \n",
    "    SVC_rbf = SVC( ) \n",
    "    SVC_rbf.fit(train_x, train_y  )\n",
    "    print \"model fitted\"\n",
    "    preds = SVC_rbf.predict( test_x ) \n",
    "    acc =  accuracy_score(test_y , preds )\n",
    "    dict[\"RBF\"] = acc\n",
    "    return dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_scores = { }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_feats = get_early_feats_fashion_mnist_training(train_fashion_x)\n",
    "fashion_feats = fashion_feats.reshape([len(fashion_feats), fashion_feats[0].shape[0]  ])\n",
    "print fashion_feats.shape \n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(fashion_feats, train_fashion_y  )\n",
    "test_fashion_feats = get_early_feats_fashion_mnist_training(test_fashion_x[:10000] ) \n",
    "preds = clf.predict(test_fashion_feats)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print accuracy_score(test_fashion_y[:10000], preds  )\n",
    "\n",
    "accuracy_scores[\"early_feats_linear\"] = accuracy_score(test_fashion_y[:10000], preds  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fashion_feats = get_feats_fashion_mnist_training(train_fashion_x)\n",
    "fashion_feats = fashion_feats.reshape([len(fashion_feats), fashion_feats[0].shape[0]  ])\n",
    "print fashion_feats.shape \n",
    "\n",
    "clf = LinearSVC()\n",
    "clf.fit(fashion_feats, train_fashion_y  )\n",
    "test_fashion_feats = get_feats_fashion_mnist_training(test_fashion_x[:10000] ) \n",
    "preds = clf.predict(test_fashion_feats)\n",
    "from sklearn.metrics import accuracy_score\n",
    "print accuracy_score(test_fashion_y[:10000], preds  )\n",
    "\n",
    "accuracy_scores[\"late_feats_linear\"] = accuracy_score(test_fashion_y[:10000], preds  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model fitted\n"
     ]
    }
   ],
   "source": [
    "accuracy_scores[\"linear_models\"] = train_linear_model( train_fashion_x , train_fashion_y, test_fashion_x[:10000] , test_fashion_y[:10000] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'linear_models': {'linear_SVM': 0.80220000000000002}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 50s - loss: 0.4843 - acc: 0.8262 - val_loss: 0.3716 - val_acc: 0.8662\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 50s - loss: 0.3441 - acc: 0.8762 - val_loss: 0.3348 - val_acc: 0.8796\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.3098 - acc: 0.8882 - val_loss: 0.3268 - val_acc: 0.8845\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2904 - acc: 0.8960 - val_loss: 0.3015 - val_acc: 0.8919\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2736 - acc: 0.9018 - val_loss: 0.2996 - val_acc: 0.8956\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2629 - acc: 0.9066 - val_loss: 0.3020 - val_acc: 0.8939\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2521 - acc: 0.9104 - val_loss: 0.2947 - val_acc: 0.8961\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2449 - acc: 0.9122 - val_loss: 0.2800 - val_acc: 0.9021\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2376 - acc: 0.9151 - val_loss: 0.2857 - val_acc: 0.9007\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2309 - acc: 0.9172 - val_loss: 0.2858 - val_acc: 0.9014\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2251 - acc: 0.9194 - val_loss: 0.2729 - val_acc: 0.9061\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2194 - acc: 0.9222 - val_loss: 0.2797 - val_acc: 0.9029\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2144 - acc: 0.9234 - val_loss: 0.2849 - val_acc: 0.9001\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2098 - acc: 0.9249 - val_loss: 0.2805 - val_acc: 0.9026\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2049 - acc: 0.9266 - val_loss: 0.2817 - val_acc: 0.9011\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.2010 - acc: 0.9279 - val_loss: 0.2779 - val_acc: 0.9021\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1973 - acc: 0.9296 - val_loss: 0.2778 - val_acc: 0.9033\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1939 - acc: 0.9307 - val_loss: 0.2713 - val_acc: 0.9068\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1906 - acc: 0.9324 - val_loss: 0.2814 - val_acc: 0.9011\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 48s - loss: 0.1871 - acc: 0.9328 - val_loss: 0.2735 - val_acc: 0.9048\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1847 - acc: 0.9337 - val_loss: 0.2883 - val_acc: 0.8996\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1810 - acc: 0.9355 - val_loss: 0.2781 - val_acc: 0.9032\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1785 - acc: 0.9370 - val_loss: 0.2650 - val_acc: 0.9087\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1751 - acc: 0.9378 - val_loss: 0.2758 - val_acc: 0.9040\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 49s - loss: 0.1733 - acc: 0.9382 - val_loss: 0.2763 - val_acc: 0.9021\n"
     ]
    }
   ],
   "source": [
    "fashion_model = Sequential()\n",
    "fashion_model.reset_states() \n",
    "fashion_model.add(Convolution2D( 64  , 3, 3 , input_shape = train_x[0].shape   ))  \n",
    "fashion_model.add(Activation('tanh'))\n",
    "fashion_model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(10))\n",
    "fashion_model.add(Activation('softmax'))\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "fashion_model.reset_states( )\n",
    "\n",
    "train_fashion_y_categorical =  keras.utils.np_utils.to_categorical(train_fashion_y  ,  10  )\n",
    "test_fashion_y_categorical =  keras.utils.np_utils.to_categorical(test_fashion_y  ,  10  )\n",
    "\n",
    "fashion_model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "fashion_history = fashion_model.fit( train_fashion_x , train_fashion_y_categorical , batch_size= 20, nb_epoch = 25, validation_data=(test_fashion_x[:10000],test_fashion_y_categorical[:10000]) )\n",
    "accuracy_scores[\"cnn_on_fashion_mnist\"] = fashion_history.history[\"val_acc\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      "50000/50000 [==============================] - 97s - loss: 6.0471 - acc: 0.5240 - val_loss: 0.6681 - val_acc: 0.7673\n",
      "Epoch 2/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.5468 - acc: 0.8090 - val_loss: 0.4720 - val_acc: 0.8416\n",
      "Epoch 3/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.4344 - acc: 0.8487 - val_loss: 0.4472 - val_acc: 0.8477\n",
      "Epoch 4/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3938 - acc: 0.8653 - val_loss: 0.3992 - val_acc: 0.8585\n",
      "Epoch 5/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3672 - acc: 0.8733 - val_loss: 0.3979 - val_acc: 0.8663\n",
      "Epoch 6/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3464 - acc: 0.8809 - val_loss: 0.3717 - val_acc: 0.8771\n",
      "Epoch 7/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3323 - acc: 0.8869 - val_loss: 0.3880 - val_acc: 0.8750\n",
      "Epoch 8/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3230 - acc: 0.8881 - val_loss: 0.3694 - val_acc: 0.8751\n",
      "Epoch 9/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3146 - acc: 0.8908 - val_loss: 0.3707 - val_acc: 0.8755\n",
      "Epoch 10/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3073 - acc: 0.8945 - val_loss: 0.3718 - val_acc: 0.8801\n",
      "Epoch 11/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.3038 - acc: 0.8949 - val_loss: 0.3803 - val_acc: 0.8777\n",
      "Epoch 12/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2977 - acc: 0.8968 - val_loss: 0.3646 - val_acc: 0.8800\n",
      "Epoch 13/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2929 - acc: 0.8994 - val_loss: 0.3608 - val_acc: 0.8788\n",
      "Epoch 14/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2913 - acc: 0.8996 - val_loss: 0.4037 - val_acc: 0.8720\n",
      "Epoch 15/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2881 - acc: 0.9018 - val_loss: 0.3714 - val_acc: 0.8798\n",
      "Epoch 16/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2859 - acc: 0.9021 - val_loss: 0.3597 - val_acc: 0.8792\n",
      "Epoch 17/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2855 - acc: 0.9012 - val_loss: 0.3755 - val_acc: 0.8784\n",
      "Epoch 18/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2808 - acc: 0.9034 - val_loss: 0.3980 - val_acc: 0.8801\n",
      "Epoch 19/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2813 - acc: 0.9026 - val_loss: 0.3840 - val_acc: 0.8821\n",
      "Epoch 20/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2798 - acc: 0.9048 - val_loss: 0.3642 - val_acc: 0.8816\n",
      "Epoch 21/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2790 - acc: 0.9037 - val_loss: 0.4115 - val_acc: 0.8791\n",
      "Epoch 22/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2766 - acc: 0.9038 - val_loss: 0.3999 - val_acc: 0.8766\n",
      "Epoch 23/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2779 - acc: 0.9051 - val_loss: 0.4034 - val_acc: 0.8756\n",
      "Epoch 24/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2752 - acc: 0.9056 - val_loss: 0.3685 - val_acc: 0.8760\n",
      "Epoch 25/25\n",
      "50000/50000 [==============================] - 96s - loss: 0.2762 - acc: 0.9046 - val_loss: 0.3977 - val_acc: 0.8731\n"
     ]
    }
   ],
   "source": [
    "custom_model = Sequential()\n",
    "custom_model.reset_states() \n",
    "custom_model.add(Convolution2D(64, 3, 3,  input_shape = train_x[0].shape, name = \"con1\" ))\n",
    "custom_model.add(Activation('relu', name= \"act1\" ))\n",
    "custom_model.add(MaxPooling2D(pool_size=(2, 2), name = \"pool1\" ))\n",
    "\n",
    "custom_model.add(Convolution2D(32, 3, 3))\n",
    "custom_model.add(Activation('relu'))\n",
    "custom_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "custom_model.add(Flatten())\n",
    "custom_model.add(Dense(10))\n",
    "custom_model.add(Activation('softmax'))\n",
    "\n",
    "custom_model.load_weights(\"mnist_original_model.h5\",by_name=True)\n",
    "\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "custom_model.compile(loss='categorical_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "train_fashion_y_categorical =  keras.utils.np_utils.to_categorical(train_fashion_y  ,  10  )\n",
    "test_fashion_y_categorical  =  keras.utils.np_utils.to_categorical(test_fashion_y  ,  10  )\n",
    "\n",
    "\n",
    "custom_history = custom_model.fit( train_fashion_x , train_fashion_y_categorical  , batch_size= 20 ,nb_epoch = 25 ,validation_data=(test_fashion_x[:10000],test_fashion_y_categorical[:10000]) )\n",
    "accuracy_scores[\"custom_on_fashion_mnist\"] = custom_history.history[\"val_acc\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_models {'linear_SVM': 0.80220000000000002}\n",
      "cnn_on_fashion_mnist 0.902099995852\n",
      "custom_on_fashion_mnist 0.873099998832\n"
     ]
    }
   ],
   "source": [
    "for ii in accuracy_scores:\n",
    "    print ii, accuracy_scores[ii]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tmh_env] *",
   "language": "python",
   "name": "conda-env-tmh_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
