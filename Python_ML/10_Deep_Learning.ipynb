{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AND 연산과 OR연산 학습이 가능한지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 1.1717188358306885, W : [[-2.1944666]\n",
      " [-1.1163056]]\n",
      "cost : 0.3871822953224182, W : [[0.7348619]\n",
      " [1.0511891]]\n",
      "cost : 0.25197702646255493, W : [[1.7701083]\n",
      " [1.8644004]]\n",
      "cost : 0.18956831097602844, W : [[2.4184332]\n",
      " [2.4519506]]\n",
      "cost : 0.15224851667881012, W : [[2.9028447]\n",
      " [2.916587 ]]\n",
      "cost : 0.12711101770401, W : [[3.2946079]\n",
      " [3.3009164]]\n",
      "accuracy : 1.0\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# AND\n",
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y_data = np.array([[0],[0],[0],[1]])\n",
    "# OR\n",
    "# y_data = np.array([[0],[1],[1],[1]])\n",
    "# XOR\n",
    "# y_data = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "# Logistic Regression\n",
    "X = tf.placeholder(shape=[None,2], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1], dtype = tf.float32)\n",
    "\n",
    "W = tf.Variable(tf.random_normal([2,1]), dtype = tf.float32)\n",
    "b = tf.Variable(tf.random_normal([1,]), dtype = tf.float32)\n",
    "\n",
    "logit= tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit, labels = Y))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(3000):\n",
    "    _, cost_value, weight_value = sess.run([train,cost,W], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 500 == 0:\n",
    "        print(\"cost : {}, W : {}\".format(cost_value, weight_value))\n",
    "\n",
    "        \n",
    "predict = tf.cast(H>0.5, dtype = tf.float32)        \n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))\n",
    "print(\"{}\".format(sess.run(predict, feed_dict={X:[[1,0]]})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple layer를 이용한 XOR문제 해결"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/28910538/53850029-4d706c80-3ffd-11e9-84d1-36fbe636a08c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://user-images.githubusercontent.com/28910538/53849515-7d1e7500-3ffb-11e9-8064-ddb6f9436943.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost : 1.6183271408081055, W : [[-0.99545586]\n",
      " [-0.61006016]]\n",
      "cost : 0.0008342807414010167, W : [[-0.99545586]\n",
      " [-0.61006016]]\n",
      "cost : 0.00045081679127179086, W : [[-0.99545586]\n",
      " [-0.61006016]]\n",
      "cost : 0.000311503914417699, W : [[-0.99545586]\n",
      " [-0.61006016]]\n",
      "cost : 0.00023920151579659432, W : [[-0.99545586]\n",
      " [-0.61006016]]\n",
      "accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [[0,0],[0,1],[1,0],[1,1]]\n",
    "y_data = [[0],[1],[1],[0]]\n",
    "\n",
    "X = tf.placeholder(shape = [None, 2], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 1], dtype = tf.float32)\n",
    "# Weight & bias\n",
    "W1 = tf.Variable(tf.random_normal([2,256]), dtype= tf.float32, name = \"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([256]), dtype= tf.float32, name = \"bias1\")\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256,512]), dtype= tf.float32, name = \"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([512]), dtype= tf.float32, name = \"bias2\")\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512,1]), dtype=tf.float32, name = \"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([1]), dtype=tf.float32, name = \"bias3\")\n",
    "# Hpyothesis\n",
    "logit = tf.matmul(layer2, W3) + b3\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = logit, labels = Y))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.05).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(10000):\n",
    "    _, cost_value, weight_value = sess.run([train, cost, W], feed_dict={X:x_data, Y:y_data})\n",
    "    if step % 2000 == 0:\n",
    "        print(\"cost : {}, W : {}\".format(cost_value, weight_value))\n",
    "        \n",
    "predict = tf.cast(H>0.5, dtype = tf.float32)\n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict={X:x_data, Y:y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "mnist.train.images.shape : (55000, 784), mnist.train.labels.shape : (55000, 10)\n",
      "cost : 1.4041918516159058\n",
      "cost : 0.3303096294403076\n",
      "cost : 0.2625373303890228\n",
      "cost : 0.12134835869073868\n",
      "cost : 0.1898123025894165\n",
      "cost : 0.3836968243122101\n",
      "cost : 0.1858980506658554\n",
      "cost : 0.08060447871685028\n",
      "cost : 0.03632713854312897\n",
      "cost : 0.02304166741669178\n",
      "accuracy : 0.9176999926567078\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot =True)\n",
    "\n",
    "print(\"mnist.train.images.shape : {}, mnist.train.labels.shape : {}\".format(mnist.train.images.shape, mnist.train.labels.shape))\n",
    "\n",
    "X = tf.placeholder(shape = [None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype = tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]), dtype = tf.float32, name = \"weight1\")\n",
    "b1 = tf.Variable(tf.random_normal([256]), dtype = tf.float32, name = \"bias1\")\n",
    "h_layer1 = tf.sigmoid(tf.matmul(X,W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 512]), dtype = tf.float32, name = \"weight2\")\n",
    "b2 = tf.Variable(tf.random_normal([512]), dtype = tf.float32, name = \"bias2\")\n",
    "h_layer2 = tf.sigmoid(tf.matmul(h_layer1,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512, 10]), dtype = tf.float32, name = \"weight3\")\n",
    "b3 = tf.Variable(tf.random_normal([10]), dtype = tf.float32, name = \"bias3\")\n",
    "logit = tf.matmul(h_layer2, W3) + b3\n",
    "H = tf.nn.softmax(logit)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits= logit, labels= Y))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_value = sess.run([train, cost], feed_dict = {X:batch_x, Y:batch_y})\n",
    "    if step % 6 == 0:\n",
    "        print(\"cost : {}\".format(cost_value))\n",
    "\n",
    "predict = tf.argmax(H, axis = 1)\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis = 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "    \n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict = {X:mnist.test.images, Y:mnist.test.labels})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습률을 높이기 위해\n",
    "- 1. sigmoid 대신 Relu\n",
    "- 2. Xavier initialization\n",
    "    - 초기 weight 설정을 0으로주거나 랜덤으로 주지않고 => weight 초기화\n",
    "    - W = np.random.randn(num_of_input, num_of_output) / np.sqrt(num_of_input / 2)\n",
    "- 3. Dropout\n",
    "    - overfitting 방지하기 위함\n",
    "    - 학습할때는 어느정도의 노드를 dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vanishing gradient problem \n",
    "- sigmoid는 0~1 값 리턴, 근데 값이 크거나 작을때의 sigmoid의 기울기는 0에 가까움\n",
    "- 역전파 오류가 반복되면 이러한 0에 가까운 값이 곱해짐으로써 학습이 더 안됨\n",
    "- 때문에 sigmoid 대신 relu를 사용\n",
    "    - relu는 음수일때는 0 양수일때는 그대로의 값 즉 기울기1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf graph 싹 다 초기화  \n",
    "- tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2575ade6330a>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\gpu_env\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "mnist.train.images.shape : (55000, 784), mnist.train.labels.shape : (55000, 10)\n",
      "cost : 0.2899751365184784\n",
      "cost : 0.07781501114368439\n",
      "cost : 0.06655004620552063\n",
      "cost : 0.04430902376770973\n",
      "cost : 0.0968281477689743\n",
      "accuracy : 0.9815000295639038\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import matplotlib\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot =True)\n",
    "\n",
    "print(\"mnist.train.images.shape : {}, mnist.train.labels.shape : {}\".format(mnist.train.images.shape, mnist.train.labels.shape))\n",
    "\n",
    "X = tf.placeholder(shape = [None, 784], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype = tf.float32)\n",
    "# 살릴 확률\n",
    "keep_prob = tf.placeholder(dtype = tf.float32)\n",
    "# Xavier_initialization\n",
    "W1 = tf.get_variable(\"weight1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), dtype = tf.float32, name = \"bias1\")\n",
    "# relu , dropout\n",
    "_h_layer1 = tf.nn.relu(tf.matmul(X,W1) + b1)\n",
    "h_layer1 = tf.nn.dropout(_h_layer1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[256, 512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]), dtype = tf.float32, name = \"bias2\")\n",
    "_h_layer2 = tf.nn.relu(tf.matmul(h_layer1,W2) + b2)\n",
    "h_layer2 = tf.nn.dropout(_h_layer2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([512, 10]), dtype = tf.float32, name = \"weight3\")\n",
    "W3 = tf.get_variable(\"weight3\", shape=[512, 10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]), dtype = tf.float32, name = \"bias3\")\n",
    "\n",
    "# logit = tf.matmul(h_layer2, W3) + b3\n",
    "# H = tf.nn.softmax(logit)\n",
    "H = tf.matmul(h_layer2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits= H, labels= Y))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_epoch = 30\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_value = sess.run([train, cost], feed_dict = {X:batch_x, Y:batch_y, keep_prob:0.7})\n",
    "    if step % 6 == 0:\n",
    "        print(\"cost : {}\".format(cost_value))\n",
    "\n",
    "predict = tf.argmax(H, axis = 1)\n",
    "correct = tf.equal(predict, tf.argmax(Y, axis = 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "    \n",
    "print(\"accuracy : {}\".format(sess.run(accuracy, feed_dict = {X:mnist.test.images, Y:mnist.test.labels, keep_prob:1.0})))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN(Convolutional Neural Netowrks)\n",
    "- 이전의 NN와 차이는  fully connected\n",
    "- CNN은 이미지 일부만을 일단 처리(Filter 이용)\n",
    "- Output size : (N-F)/stride + 1\n",
    "- activation map으로 가기전에 relu 적용\n",
    "- 그리고 사이즈 줄여주기위해 Pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input의 shape : (1, 3, 3, 1), filter의 shape : (2, 2, 1, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 12., 120.,   0.],\n",
       "         [ 16., 160.,   0.]],\n",
       "\n",
       "        [[ 24., 240.,   0.],\n",
       "         [ 28., 280.,   0.]]]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# (1,3,3,1) 이미지개수, 가로,세로, color\n",
    "# 맨 앞에꺼를 행으로 생각하면서 풀어가면 됨\n",
    "# 1을 행으로생각 3,3,1열\n",
    "# 3을 행으로 생각 3,1열\n",
    "# 3을 행으로 생각 1열\n",
    "input_img = np.array([[[[1],[2],[3]],\n",
    "                       [[4],[5],[6]],\n",
    "                       [[7],[8],[9]]]], dtype = np.float32)\n",
    "# (1,2,2,1)\n",
    "# W = np.array([[[[1]],[[1]]],\n",
    "#               [[[1]],[[1]]]],dtype = np.float32)\n",
    "# (2,2,1,3) => 가로 세로 color 필터 개수\n",
    "W = np.array([[[[1,10,-1]],[[1,10,-1]]],[[[1,10,-1]],[[1,10,-1]]]])\n",
    "# ()\n",
    "print(\"input의 shape : {}, filter의 shape : {}\".format(input_img.shape, W.shape))\n",
    "# strides를 4차원으로 적어줌 => 앞의 shape처럼\n",
    "# 앞과 뒤는 4차원 맞추기위한 패딩 중간 1,1이 행으로1 열로1씩 stride를 적용\n",
    "# VALID는 패딩을 안한다는거 SAME은 원본과 아웃풋 크기 같게하겠다는(패딩을 하겠다는)\n",
    "\n",
    "conv2d = tf.nn.conv2d(input_img, W, strides =[1,1,1,1], padding=\"VALID\")\n",
    "conv2d = tf.nn.relu(conv2d)\n",
    "# 위 두줄을 아래 한줄로 표현\n",
    "# conv2d = tf.layers.conv2d(inputs=input_img, filters=32, kernel_size = [2,2], padding=\"VALID\", strides=1, activation = tf.nn.relu)\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[4.],\n",
       "         [3.]],\n",
       "\n",
       "        [[2.],\n",
       "         [1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# image = > (1,2,2,1)\n",
    "images = np.array([[[[4],[3]],[[2],[1]]]], dtype = np.float32)\n",
    "print(images.shape)\n",
    "pool = tf.nn.max_pool(images, ksize=[1,2,2,1], strides =[1,1,1,1], padding=\"SAME\")\n",
    "sess.run(pool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.swapaxes(reulst, sh1, sh2)\n",
    "- sh1과 sh2축을 바꿈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1, 14, 14, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "img = mnist.train.images[0]\n",
    "plt.imshow(img.reshape(28,28), cmap=\"Greys\")\n",
    "plt.show()\n",
    "# 1깊이의 28x28짜리 1개\n",
    "img = img.reshape((1,28,28,1))\n",
    "print(img.shape)\n",
    "# 3x3짜리 1깊이 5개\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]), dtype = tf.float32)\n",
    "# strides가 1x1일 때 padding이 SAME, Strides가 2x2면 줄어들게 됨 padding이 SAME이여도\n",
    "conv2d = tf.nn.conv2d(img, W, strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "result = sess.run(conv2d)\n",
    "print(result.shape)\n",
    "## 1,14,14,5의 shape으로 이미지 뽑기 위해  axis 변경 해서 (5,14,14,1) 의 형태로 변형\n",
    "# 0번째와 3번째를 바꿈\n",
    "result = np.swapaxes(result, 0,3)\n",
    "# 1행5열 짜리 axes에 넣어줌\n",
    "fig, axes = plt.subplots(1,5)\n",
    "\n",
    "for idx, t_img in enumerate(result):\n",
    "    axes[idx].imshow(t_img.reshape(14,14), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n",
      "(1, 7, 7, 5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "img = mnist.train.images[0]\n",
    "plt.imshow(img.reshape(28,28), cmap=\"Greys\")\n",
    "plt.show()\n",
    "# 1깊이의 28x28짜리 1개\n",
    "img = img.reshape((1,28,28,1))\n",
    "print(img.shape)\n",
    "# 3x3짜리 1깊이 5개 필터\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]), dtype = tf.float32)\n",
    "# strides가 1x1일 때 padding이 SAME, Strides가 2x2면 줄어들게 됨 padding이 SAME이여도\n",
    "conv2d = tf.nn.conv2d(img, W, strides=[1,2,2,1], padding=\"SAME\")\n",
    "# tf.nn.relu\n",
    "conv2d = tf.nn.relu(conv2d)\n",
    "# Max Pooling (sub sampling)\n",
    "pool = tf.nn.max_pool(conv2d, ksize = [1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "result = sess.run(pool)\n",
    "print(result.shape)\n",
    "\n",
    "result = np.swapaxes(result, 0,3)\n",
    "# 1행5열 짜리 axes에 넣어줌\n",
    "fig, axes = plt.subplots(1,5)\n",
    "\n",
    "for idx, t_img in enumerate(result):\n",
    "    axes[idx].imshow(t_img.reshape(7,7), cmap=\"Greys\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(?, 28, 28, 32)\n",
      "(?, 7, 7, 64)\n",
      "cost_val : 0.10161174088716507\n",
      "cost_val : 0.18134351074695587\n",
      "cost_val : 0.06131645664572716\n",
      "cost_val : 0.06951934844255447\n",
      "cost_val : 0.15346868336200714\n",
      "accuracy : 0.9831\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 0. Data load\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# 1. CNN - 특징 추출\n",
    "print(mnist.train.images.shape)\n",
    "print(mnist.train.labels.shape)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape = [None, 784], dtype= tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype= tf.float32)\n",
    "# input conv image\n",
    "X_img = tf.reshape(X, shape = [-1, 28,28,1])\n",
    "# drop out\n",
    "keep_rate = tf.placeholder(dtype = tf.float32)\n",
    "\n",
    "# 표준편차를 작게 줘서 비슷한 값 뽑히게\n",
    "# 3x3 필터(1차원) 32개\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01))\n",
    "# conv ~ 28*28(1d) 32개\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "# relu\n",
    "L1 = tf.nn.relu(L1)\n",
    "print(L1.shape)\n",
    "# 2x2 Pooling 14*14(1d) 32개 \n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "#\n",
    "L2 = tf.layers.conv2d(inputs=L1, filters=64, kernel_size =[3,3], padding=\"SAME\", strides = 1, activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(inputs = L2, pool_size=[2,2],padding=\"SAME\",strides = 2)\n",
    "\n",
    "print(L2.shape)\n",
    "\n",
    "###FC\n",
    "L2 = tf.reshape(L2, shape=[-1,7*7*64])\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape=[7*7*64,256], initializer= tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]), name = \"bias2\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W2)+b2)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob = keep_rate)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[256,256], initializer= tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([256]), name = \"bias3\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W3)+b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob = keep_rate)\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,10], initializer= tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([10]), name = \"bias4\")\n",
    "\n",
    "H = tf.matmul(layer2, W4) + b4\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=H, labels=Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "train_epoch = 10\n",
    "batch_size = 100\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train, cost], feed_dict = {X:batch_x, Y:batch_y,keep_rate:0.7})\n",
    "    if step%2 == 0:\n",
    "        print(\"cost_val : {}\".format(cost_val))\n",
    "\n",
    "predict = tf.argmax(H,axis = 1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_sum(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "result_sum = 0\n",
    "\n",
    "num_of_iter = int(mnist.test.num_examples/batch_size)\n",
    "for i in range(num_of_iter):\n",
    "    batch_x, batch_y = mnist.test.next_batch(batch_size)\n",
    "    correct_num = sess.run(accuracy, feed_dict={X:batch_x,\n",
    "                                             Y:batch_y,\n",
    "                                             keep_rate : 1.0})\n",
    "    result_sum += correct_num\n",
    "result = result_sum/mnist.test.num_examples\n",
    "\n",
    "print(\"accuracy : {}\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "(?, 28, 28, 1)\n",
      "(?, 24, 24, 10)\n",
      "(?, 12, 12, 10)\n",
      "(?, 8, 8, 20)\n",
      "(?, 4, 4, 20)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.contrib.layers' has no attribute 'xaviers_initializer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-152-f715bbf2edaa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m W1 = tf.get_variable(\"weight1\", shape = [4*4*20, 100],\n\u001b[1;32m---> 33\u001b[1;33m                     initializer=tf.contrib.layers.xaviers_initializer())\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[0mb1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bias1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0m_fc_layer1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mflatten_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.contrib.layers' has no attribute 'xaviers_initializer'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "################ 0. data load\n",
    "tf.reset_default_graph()\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "# mnist (55000, 28*28)\n",
    "################ 1. placeholder\n",
    "X = tf.placeholder(shape = [None, 28*28], dtype = tf.float32)\n",
    "Y = tf.placeholder(shape = [None, 10], dtype = tf.float32)\n",
    "# drop oout\n",
    "set_prob = tf.placeholder(dtype = tf.float32)\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])\n",
    "################ conv_layer 1\n",
    "print(X_img.shape)\n",
    "filter_1 = tf.Variable(tf.random_normal([5,5,1,10], stddev=0.1), dtype = tf.float32)\n",
    "conv_layer1 = tf.nn.conv2d(X_img, filter_1, strides=[1,1,1,1], padding=\"VALID\")\n",
    "print(conv_layer1.shape)\n",
    "conv_layer1 = tf.nn.relu(conv_layer1)\n",
    "conv_layer1 = tf.nn.max_pool(conv_layer1,ksize = [1,2,2,1],strides= [1,2,2,1], padding=\"SAME\")\n",
    "print(conv_layer1.shape)\n",
    "################ conv_layer 2\n",
    "filter_2 = tf.Variable(tf.random_normal([5,5,10,20], stddev=0.1), dtype = tf.float32)\n",
    "conv_layer2 = tf.nn.conv2d(conv_layer1, filter_2, strides=[1,1,1,1], padding=\"VALID\")\n",
    "print(conv_layer2.shape)\n",
    "conv_layer2 = tf.nn.relu(conv_layer2)\n",
    "conv_layer2 = tf.nn.max_pool(conv_layer2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "print(conv_layer2.shape)\n",
    "################ Fully Connected layer\n",
    "flatten_X = tf.reshape(conv_layer2, [-1, 4*4*20])\n",
    "\n",
    "W1 = tf.get_variable(\"weight1\", shape = [4*4*20, 100],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(\"bias1\", tf.random_normal([100]), dtype = tf.float32)\n",
    "_fc_layer1 = tf.nn.relu(tf.matmul(flatten_X, W1)+b)\n",
    "fc_layer1 = tf.nn.dropout(_fc_layer1, keep_prob=set_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", shape = [100, 10],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(\"bias2\", tf.random_normal([10]), dtype = tf.float32)\n",
    "\n",
    "logit = tf.matmul(fc_layer1, W2)+b\n",
    "H = tf.nn.softmax(logit)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit, labels = Y))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[GPU_ENV]",
   "language": "python",
   "name": "gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
