{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Pytorch tuto](https://9bow.github.io/PyTorch-tutorials-kr-0.3.1/beginner/deep_learning_60min_blitz.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch란\n",
    "> python 기반의 과학 연산 패키지\n",
    "\n",
    "- numpy를 대체, GPU의 연산력을 사용\n",
    "- 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼\n",
    "\n",
    "## Tensors\n",
    "- numpy의 ndarray와 유사할 뿐만 아니라, GPU를 사용한 연산 가속도 지원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.0811e-23, 8.5339e-43, 3.0811e-23],\n",
      "        [8.5339e-43, 3.0811e-23, 8.5339e-43],\n",
      "        [3.0811e-23, 8.5339e-43, 3.0806e-23],\n",
      "        [8.5339e-43, 3.0806e-23, 8.5339e-43],\n",
      "        [3.0810e-23, 8.5339e-43, 3.0810e-23]])\n"
     ]
    }
   ],
   "source": [
    "# 초기화되지 않은 5x3 행렬 생성\n",
    "x = torch.Tensor(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3066, 0.2013, 0.5141],\n",
      "        [0.0769, 0.9988, 0.5029],\n",
      "        [0.1234, 0.0809, 0.8736],\n",
      "        [0.3147, 0.6114, 0.5459],\n",
      "        [0.5037, 0.6788, 0.6910]])\n"
     ]
    }
   ],
   "source": [
    "# 무작위로 초기화된 행렬 생성\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "# 행렬 크기 구함\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.Size`는 튜플과 같으며 모든 튜플 연산에 사용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산\n",
    "- 연산을 위한 여러가지 문법 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7308, 1.1302, 1.0226],\n",
      "        [0.6929, 1.6696, 0.8362],\n",
      "        [1.0237, 0.2497, 1.7533],\n",
      "        [1.2015, 0.8582, 1.1531],\n",
      "        [0.6830, 1.5065, 1.2289]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7308, 1.1302, 1.0226],\n",
      "        [0.6929, 1.6696, 0.8362],\n",
      "        [1.0237, 0.2497, 1.7533],\n",
      "        [1.2015, 0.8582, 1.1531],\n",
      "        [0.6830, 1.5065, 1.2289]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7308, 1.1302, 1.0226],\n",
      "        [0.6929, 1.6696, 0.8362],\n",
      "        [1.0237, 0.2497, 1.7533],\n",
      "        [1.2015, 0.8582, 1.1531],\n",
      "        [0.6830, 1.5065, 1.2289]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.Tensor(5, 3)\n",
    "torch.add(x, y, out=result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### in-place\n",
    "> tensor의 값을 변경하는 연산은 `_`를 접미사로 가짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0374, 1.3315, 1.5367],\n",
      "        [0.7699, 2.6684, 1.3390],\n",
      "        [1.1471, 0.3305, 2.6269],\n",
      "        [1.5162, 1.4697, 1.6990],\n",
      "        [1.1867, 2.1853, 1.9199]])\n"
     ]
    }
   ],
   "source": [
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2013, 0.9988, 0.0809, 0.6114, 0.6788])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## view(reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy 변환(Bridge)\n",
    "- Torch Tensor를 numpy 배열로 변환하거나 그 반대"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy 배열을 Torch Tensor로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Tensors\n",
    "- `.cuda()`메소드를 사용하여 Tensor를 GPU상으로 옮길 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6293,  2.8142, -0.2479, -2.4970],\n",
      "        [ 0.8423, -0.6348, -1.3439,  0.1074],\n",
      "        [-0.2339, -0.0628, -0.6163, -2.5177],\n",
      "        [ 1.1510,  2.1147,  1.0034,  3.0740]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.view((4,4)).cuda()\n",
    "    print(x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd : 자동 미분\n",
    "- Pytorch의 모든 신경망의 중심에는 `autograd`패키지가 있음\n",
    "- Tensor의 모든 연산에 대해 자동 미분을 제공\n",
    "    - 실행-기반-정의 프레임워크\n",
    "    - 역전파는 학습 과정의 매 단계마다 달라짐\n",
    "    \n",
    "## 변수(Variable)\n",
    "- `autograd.Variable`\n",
    "    - Tensor를 감싸고있으며, Tensor 기반으로 정의된 거의 대부분의 연산을 지원\n",
    "    - 계산이 완료된 후 `.backward()`를 호출하여 모든 변화도(gradient)를 자동으로 계산\n",
    "    - `.data`속성을 사용하여 tensor 자체에 접근할 수 있으며, 이 변수와 관련된 변화도는 `.grad`에 누적됨\n",
    "        - ![image](https://user-images.githubusercontent.com/28910538/63827377-db6e5400-c99d-11e9-8b4d-c93d5803a673.png)\n",
    "\n",
    "## Fcuntion\n",
    "- Variable과 Function은 상호 연결되어 있음\n",
    "- 모든 연산 과정을 부호화(encode)하여 순환하지 않은 그래프를 생성\n",
    "- 각 변수는 `grad_fn`속성을 갖고있음\n",
    "    - `Variable`을 생성한 Function을 참조하고 있음\n",
    "        - 단 사용자가 만든 Variable은 예외(이 때의 grad_fn은 None\n",
    "- 도함수를 계산하기 위해서는 Variable의 `.backward()`를 호출\n",
    "- `Variable`이 스칼라인 경우에는 `backward`에 인자를 정해줄 필요가 없음, 하지만 여러 개의 요소를 갖고 있을 때는 tensor의 모양을 gradient의 인자로 지정할 필요가 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.ones(2,2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002611DBF0240>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변화도(Gradient)\n",
    "- `out.backward()`는 `out.backward(torch.Tensor([1,0]))`와 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-880.0632, -283.4705, -426.4141], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "gradient = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradient)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망(Neural Networks)\n",
    "- `torch.nn`패키지 사용해 쉽게 생성 가능\n",
    "- 모델을 정의하고 미분하는데 `autograd`를 사용\n",
    "- `nn.Module`은 계층과 `output`을 반환하는 `forward(input)`메서드를 포함하고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 전형적인 학습 과정\n",
    "- 학습 가능한 매개변수(또는 가중치)를 갖는 신경망을 정의\n",
    "- 데이터 셋 입력을 반복\n",
    "- 입력을 신경망에서 처리\n",
    "- loss(출려과 정답이 얼마나 떨어져있는지)를 계산\n",
    "- 변화도(gradient)를 신경망의 매개변수들에 역으로 전파\n",
    "- 신경망의 가중치 갱신(weight = learning_rate * wieght * gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input 채널, output 채널, kerenl\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, X):\n",
    "        size = x.size()[1:]\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`forward`함수만 정의하고나면 변화도 계산하는 `backward`함수는 `autograd`를 사용하여 자동으로 정의됨, 모델의 학습 가능한 매개변수들은 `net.parameters()`에 의해 반환 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
