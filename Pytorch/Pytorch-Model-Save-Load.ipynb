{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장하기 & 불러오기\n",
    "- 3가지 핵심함수\n",
    "    1. `torch.save` : 직렬화된 객체를 디스크에 저장\n",
    "        - Python의 pickle(리스트나 클래스같은 자료형을 저장/로드)을 사용하여 직렬화\n",
    "        - 모든 종류의 객체의 모델, Tensor 및 사전을 저장\n",
    "    2. 'torch.load:pickle`을 사용하여 저장된 객체 파일들을 역직렬화하여 메모리에 올림\n",
    "    3. `torch.nn.Module.load_state_dict` : state_dict 사용하여 모델의 매겨변수를 불러움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## state_dict란\n",
    "> 한마디로 model layer KEY tensor VALUE의 dictionary\n",
    "\n",
    "- Pytorch에서 `torch.nn.Module` 모델의 학습 가능한 매개변수들은 모델의 매개변수에 포함되어 있음\n",
    "    - `model.parameter()`로 접근\n",
    "- 간단하게 말해 각 계층을 매개변수 텐서로 매핑되는 Python dictionary 객체\n",
    "    - 학습 가능한 매개변수를 갖는 계층(합성곱 계층, 선형 계층 등) 및 등록된 버퍼들만이 모델의 state_dict에 항목을 가짐\n",
    "    - torch.optim또한 옵티마이저의 상태 뿐만 아니라 사용된 하이퍼 매개변수 정보를 포함된 state_dict를 가짐\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:51:21.797218Z",
     "start_time": "2019-10-01T09:51:21.603676Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:51:21.812207Z",
     "start_time": "2019-10-01T09:51:21.802205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model state_dict :\n",
      "conv1.weight\ttorch.Size([6, 3, 5, 5])\n",
      "conv1.bias\ttorch.Size([6])\n",
      "conv2.weight\ttorch.Size([16, 6, 5, 5])\n",
      "conv2.bias\ttorch.Size([16])\n",
      "fc1.weight\ttorch.Size([120, 400])\n",
      "fc1.bias\ttorch.Size([120])\n",
      "fc2.weight\ttorch.Size([84, 120])\n",
      "fc2.bias\ttorch.Size([84])\n",
      "fc3.weight\ttorch.Size([10, 84])\n",
      "fc3.bias\ttorch.Size([10])\n",
      "Optimizer state_dict :\n",
      "state\t{}\n",
      "param_groups\t[{'lr': 0.001, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'params': [2883275561504, 2883275721032, 2883275721320, 2883275721392, 2883275721464, 2883275721536, 2883275721608, 2883275721680, 2883275721752, 2883275721824]}]\n"
     ]
    }
   ],
   "source": [
    "class TheModelClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TheModelClass, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = TheModelClass()\n",
    "\n",
    "# init optim\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# model의 state_dict\n",
    "print(f'Model state_dict :')\n",
    "for param_tensor in model.state_dict():\n",
    "    print(f'{param_tensor}\\t{model.state_dict()[param_tensor].size()}')\n",
    "    \n",
    "# optim의 state_dict 출력\n",
    "print('Optimizer state_dict :')\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(f'{var_name}\\t{optimizer.state_dict()[var_name]}')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론(interface)를 위해 모델 저장/로드\n",
    "- state_dict 저장/로드\n",
    "- `pt`나 `pth` 확장자 주로 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:54:14.934673Z",
     "start_time": "2019-10-01T09:54:14.930684Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "PATH = './data/model_weight/test_sd.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:53:24.112242Z",
     "start_time": "2019-10-01T09:53:24.091260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval() # 드롭아웃 및 배치 정규화를 평가 모드로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 전체 모델 저장/불러오기\n",
    "- Python의 `pickle`모듈을 사용\n",
    "    - 단점 : 모델 그 자체를 저장하지 않기 떄문에 직렬화된 데이터가 모델을 저장할 때 특정 클래스/디렉터리 경로에 얽매임\n",
    "        - 그래서 리펙토링 후 혹은 다른 프로젝트에서 만든 모델 사용하면 안될 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:54:25.404538Z",
     "start_time": "2019-10-01T09:54:25.394541Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type TheModelClass. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# save\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:54:46.307850Z",
     "start_time": "2019-10-01T09:54:46.299366Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추론 / 학습 재개를 위한 일반 체크포인트 저장/불러오기\n",
    "- 반드시 model의 state_dict보다 많은 것들을 저장해야함\n",
    "- 모델이 학습을 하며 갱신되는 버퍼와 매개변수가 포함된 optimizer의 state_dict도 함께 저장\n",
    "    - 그 외에도 마지막 epoch, 최근에 기록된 학습 손실, 외부 torch.nn.Embedding 계층 등도 함께 저장\n",
    "- 여러가지를 저장하려면 dictionary 자료형으로 만든 후 `torch.save()`를 사용해 직렬화\n",
    "    - 이러한 체크포인트를 저장할 때는 `.tar`확장자를 사용하는 것이 일반적\n",
    "- 항목들을 불러올 때에는 먼저 모델과 옵티마이저를 초기화한 후 `torch.load()`를 사용하여 사전을 불러옴\n",
    "- 추론 실행전에는 반드시 `model.eval()`을 호출하여 드롭아웃, 배치 정규화를 평가모드로 설정\n",
    "    - 학습을 계속 하려면 `model.train()`로 전환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T09:58:25.734816Z",
     "start_time": "2019-10-01T09:58:25.730808Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "epoch = 10\n",
    "loss = 0.0\n",
    "torch.save({'epoch' : epoch,\n",
    "            'model_state_dict' : model.state_dict(),\n",
    "            'optimizer_state_dict' : optimizer.state_dict(),\n",
    "            'loss' : loss,\n",
    "           }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:04:01.700084Z",
     "start_time": "2019-10-01T10:04:01.691633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "model = TheModelClass()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:07:22.023750Z",
     "start_time": "2019-10-01T10:07:22.019251Z"
    }
   },
   "source": [
    "## 여러개의 모델을 하나의 파일에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:10:30.480743Z",
     "start_time": "2019-10-01T10:10:30.473223Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "modelA = TheModelClass()\n",
    "modelB = TheModelClass()\n",
    "optimizerA = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerB = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "torch.save({\n",
    "            'modelA_state_dict' : modelA.state_dict(),\n",
    "            'modelB_state_dict' : modelB.state_dict(),\n",
    "            'optimizerA_state_dict' : optimizerA.state_dict(),\n",
    "            'optimizerB_state_dict' : optimizerB.state_dict(),\n",
    "            }, PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:12:41.956317Z",
     "start_time": "2019-10-01T10:12:41.946833Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "modelA = TheModelClass()\n",
    "modelB = TheModelClass()\n",
    "optimizerA = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "optimizerB = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['modelA_state_dict'])\n",
    "modelB.load_state_dict(checkpoint['modelB_state_dict'])\n",
    "optimizerA = checkpoint['optimizerA_state_dict']\n",
    "optimizerB = checkpoint['optimizerB_state_dict']\n",
    "\n",
    "modelA.eval()\n",
    "modelB.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 모델의 매개변수를 사용하여 빠르게 모델 시작하기\n",
    "- 몇몇 key를 제외하고 state_dict의 일부를 불러오거나 적재하려는 모델보다 더 많은 키를 갖고 있는 state_dict를 불러올 때\n",
    "     - `load_state_dict()`함수에서 `strict`인자를 False로 설정\n",
    "             - 일치하지 않는 키들을 무시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:13:50.279058Z",
     "start_time": "2019-10-01T10:13:50.276069Z"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "torch.save(modelA.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:14:28.931081Z",
     "start_time": "2019-10-01T10:14:28.924129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load\n",
    "modelB = TheModelClass()\n",
    "modelB.load_state_dict(torch.load(PATH), strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다른 device설정으로 model 불러올 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T10:22:21.598581Z",
     "start_time": "2019-10-01T10:22:19.049819Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TheModelClass(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU로 저장하고 CPU로 불러올 때\n",
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device('cpu')\n",
    "model = TheModelClass()\n",
    "# map_location 인자를 사용해 CPU 장치에 동적으로 재배치\n",
    "model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "\n",
    "\n",
    "# GPU로 저장하고 GPU로 불러올 때 \n",
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device('cuda')\n",
    "model = TheModelClass()\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "# CUDA에 최적화된 모델로 변환\n",
    "model.to(device)\n",
    "# model에서 사용하는 input들은 input.to(device)를 호출해줘야 함 -> 복사본 리턴하니까\n",
    "# input = input.to(device)로 받아줘야 함\n",
    "\n",
    "\n",
    "# CPU로 저장하고 GPU로 불러올 때 \n",
    "# save\n",
    "torch.save(model.state_dict(), PATH)\n",
    "# load\n",
    "device = torch.device('cuda')\n",
    "model = TheModelClass()\n",
    "# map_location 인자를 사용해 GPU 장치에 동적으로 재배치\n",
    "model.load_state_dict(torch.load(PATH, map_location='cuda:0'))\n",
    "model.to(device)\n",
    "# model에서 사용하는 input들은 input.to(device)를 호출해줘야 함 -> 복사본 리턴하니까\n",
    "# input = input.to(device)로 받아줘야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytch_env] *",
   "language": "python",
   "name": "conda-env-pytch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
