{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Torch Script](https://tutorials.pytorch.kr/beginner/Intro_to_TorchScript_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 기존 모듈 추적\n",
    "- 스크립트를 사용하여 모듈을 직접 컴파일\n",
    "- 두 가지 접근 방식을 구성하는 방법\n",
    "- TorchScript 모듈 저장 및 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T07:58:52.256934Z",
     "start_time": "2019-10-08T07:58:52.252971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 모델 작성의 기초\n",
    "- Module은 Pytorch의 기본 구성 단위\n",
    "    1. 호출을 위해 모듈을 준비하는 생성자\n",
    "    2. `Parameters` 및 하위 집합 `Modules`\n",
    "        - 생성자에 의해 초기화되며 호출 중에 모듈에 의해 사용될 수 있음\n",
    "    3. `forward`기능\n",
    "        - 모듈이 호출 될 때 실행되는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T08:01:38.619296Z",
     "start_time": "2019-10-08T08:01:38.612755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5601, 0.2557, 0.7294, 0.1307],\n",
      "        [0.7899, 0.6791, 0.8398, 0.7546],\n",
      "        [0.5563, 0.6946, 0.7326, 0.4131]])\n",
      "tensor([[0.5601, 0.2557, 0.7294, 0.1307],\n",
      "        [0.7899, 0.6791, 0.8398, 0.7546],\n",
      "        [0.5563, 0.6946, 0.7326, 0.4131]])\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "    # 모듈이 호출 될 때 실행\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(x + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "x = torch.rand(3, 4)\n",
    "h = torch.rand(3, 4)\n",
    "print(my_cell(x, h)[0])\n",
    "print(my_cell(x, h)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__위에서__\n",
    "1. 하위 클래스를 만드는 클래스를 만듬\n",
    "    - `torch.nn.Module`\n",
    "2. 생성자를 정의\n",
    "    - `super(class, self).__init__()\n",
    "3. `forwad` 두 개의 입력을 받아 두 개의 출력을 반환하는 함수 정의\n",
    "\n",
    "- 모델을 인스턴스화하고, x, h 를 (3,4)의 임의의값으로 셀 호출 => forward "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T08:07:41.974565Z",
     "start_time": "2019-10-08T08:07:41.941490Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[ 0.3063, -0.3306,  0.6263,  0.2166],\n",
      "        [ 0.5449,  0.0184,  0.7154,  0.5830],\n",
      "        [ 0.2641,  0.0472,  0.5797,  0.2279]], grad_fn=<TanhBackward>), tensor([[ 0.3063, -0.3306,  0.6263,  0.2166],\n",
      "        [ 0.5449,  0.0184,  0.7154,  0.5830],\n",
      "        [ 0.2641,  0.0472,  0.5797,  0.2279]], grad_fn=<TanhBackward>))\n"
     ]
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "# 프린트 출력으로 Module을 시각적으로 볼 수 있음\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__위에서__\n",
    "\n",
    "- `self.linear` 속성 추가하고 `forwad`함수 호출\n",
    "- 계층구조를 구축한 Module\n",
    "- print 출력문으로 Module을 시각화할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:12:26.704746Z",
     "start_time": "2019-10-08T09:12:26.678740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyCell(\n",
      "  (dg): MyDecisionGate()\n",
      "  (linear): Linear(in_features=4, out_features=4, bias=True)\n",
      ")\n",
      "(tensor([[0.1294, 0.5614, 0.7005, 0.2993],\n",
      "        [0.6078, 0.8134, 0.7728, 0.7225],\n",
      "        [0.3048, 0.7784, 0.6045, 0.5626]], grad_fn=<TanhBackward>), tensor([[0.1294, 0.5614, 0.7005, 0.2993],\n",
      "        [0.6078, 0.8134, 0.7728, 0.7225],\n",
      "        [0.3048, 0.7784, 0.6045, 0.5626]], grad_fn=<TanhBackward>))\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "\n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        # 호출될 때 forward 실행\n",
    "        self.dg = MyDecisionGate()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "\n",
    "my_cell = MyCell()\n",
    "print(my_cell)\n",
    "print(my_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__위에서__\n",
    "\n",
    "- `MyDecisionGate`를 통해 제어흐름을 사용\n",
    "- 많은 프레임워크는 완전한 프로그램 표현에 대한 상징적 파생물을 계산하는 접근법이지만, `Pytorch`에서는 `Gradient-tape`를 사용\n",
    "    - 정방향 단계로 수행하는 모든 연산 기억하고, 역방향 단계로 거꾸로 연산들을 재생(autograd 작동 방식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TorchScript의 기초\n",
    "- TorchScript는 Pytorch의 유연하고 동적인 특성을 고려하여 모델의 정의를 캡처하는 도구를 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:26:15.653771Z",
     "start_time": "2019-10-08T09:26:15.638288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TracedModule[MyCell](\n",
      "  (linear): TracedModule[Linear]()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
       "         [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
       "         [ 0.9317, -0.3142, -0.6642,  0.8332]],\n",
       "        grad_fn=<DifferentiableGraphBackward>),\n",
       " tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
       "         [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
       "         [ 0.9317, -0.3142, -0.6642,  0.8332]],\n",
       "        grad_fn=<DifferentiableGraphBackward>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "        \n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.linear(x) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell()\n",
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "# TraceModule 인스턴스\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell)\n",
    "traced_cell(x,h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TorchScript는 일반적으로 딥러닝에서 그래프라고하는 중간표현(또는 IR)에 정의를 기록\n",
    "- .graph속성을 사용하여 그래프를 검사할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:30:34.625767Z",
     "start_time": "2019-10-08T09:30:34.621802Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit.TopLevelTracedModule"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(traced_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:26:35.314031Z",
     "start_time": "2019-10-08T09:26:35.310047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%self : ClassType<MyCell>,\n",
      "      %input : Float(3, 4),\n",
      "      %h : Float(3, 4)):\n",
      "  %1 : ClassType<Linear> = prim::GetAttr[name=\"linear\"](%self)\n",
      "  %weight : Tensor = prim::GetAttr[name=\"weight\"](%1)\n",
      "  %bias : Tensor = prim::GetAttr[name=\"bias\"](%1)\n",
      "  %6 : Float(4!, 4!) = aten::t(%weight), scope: MyCell/Linear[linear] # C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\torch\\nn\\functional.py:1369:0\n",
      "  %7 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\torch\\nn\\functional.py:1369:0\n",
      "  %8 : int = prim::Constant[value=1](), scope: MyCell/Linear[linear] # C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\torch\\nn\\functional.py:1369:0\n",
      "  %9 : Float(3, 4) = aten::addmm(%bias, %input, %6, %7, %8), scope: MyCell/Linear[linear] # C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\torch\\nn\\functional.py:1369:0\n",
      "  %10 : int = prim::Constant[value=1](), scope: MyCell # <ipython-input-18-2798a6abece9>:7:0\n",
      "  %11 : Float(3, 4) = aten::add(%9, %h, %10), scope: MyCell # <ipython-input-18-2798a6abece9>:7:0\n",
      "  %12 : Float(3, 4) = aten::tanh(%11), scope: MyCell # <ipython-input-18-2798a6abece9>:7:0\n",
      "  %13 : (Float(3, 4), Float(3, 4)) = prim::TupleConstruct(%12, %12)\n",
      "  return (%13)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 저 수준의 정보\n",
    "print(traced_cell.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:27:20.328790Z",
     "start_time": "2019-10-08T09:27:20.325817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  _0 = self.linear\n",
      "  weight = _0.weight\n",
      "  bias = _0.bias\n",
      "  _1 = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1)\n",
      "  _2 = torch.tanh(torch.add(_1, h, alpha=1))\n",
      "  return (_2, _2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GIL(Global Interpreter Lock) : 컴퓨터 언어 인터프리터에서 스레드 실행을 동기화하여 한 번에 하나의 기본 스레드만 실행할 수 있도록하는 메커니즘\n",
    "    - 멀티 코어 프로세스에서 실행되더라도 한 번에 하나의 스레드만 실행\n",
    "\n",
    "### TorchScript를 사용하는 이유\n",
    "1. TorchScript코드는 기본적으로 제한된 Python 자체 인터프리터에서 호출할 수 있음\n",
    "    - 이 인터프리터는 GIL을 얻지않으므로 동일한 인스턴스에서 동시에 많은 요청을 처리할 수 있음\n",
    "2. 이 형식을 사용하면 전체 모델을 디스크에 저장하고 Python 이외의 언어로 작성된 서버와 같은 다른 환경에로드할 수 있음\n",
    "3. TorchScript는 코드에서 컴파일러 최적화를 수행하여 보다 효율적인 실행을 제공할 수 있는 표현을 제공\n",
    "4. TorchScript를 사용하면 개별 연산자보다 프로그램을 더 넓게 볼 수 있는 많은 백엔드/장치 런타임과 인터페이스할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:41:29.962757Z",
     "start_time": "2019-10-08T09:41:29.957733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
      "        [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
      "        [ 0.9317, -0.3142, -0.6642,  0.8332]], grad_fn=<TanhBackward>), tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
      "        [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
      "        [ 0.9317, -0.3142, -0.6642,  0.8332]], grad_fn=<TanhBackward>))\n",
      "(tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
      "        [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
      "        [ 0.9317, -0.3142, -0.6642,  0.8332]],\n",
      "       grad_fn=<DifferentiableGraphBackward>), tensor([[ 0.6862,  0.3827, -0.3673,  0.5626],\n",
      "        [ 0.4641,  0.1894, -0.0544,  0.5898],\n",
      "        [ 0.9317, -0.3142, -0.6642,  0.8332]],\n",
      "       grad_fn=<DifferentiableGraphBackward>))\n"
     ]
    }
   ],
   "source": [
    "# 동일한 결과\n",
    "print(my_cell(x, h))\n",
    "print(traced_cell(x, h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스크립트를 사용하여 모듈 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:45:45.360984Z",
     "start_time": "2019-10-08T09:45:45.348588Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  _0 = self.linear\n",
      "  weight = _0.weight\n",
      "  bias = _0.bias\n",
      "  x = torch.addmm(bias, input, torch.t(weight), beta=1, alpha=1)\n",
      "  _1 = torch.tanh(torch.add(x, h, alpha=1))\n",
      "  return (_1, _1)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\pytch_env\\lib\\site-packages\\ipykernel_launcher.py:3: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "class MyDecisionGate(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        if x.sum() > 0:\n",
    "            return x\n",
    "        else:\n",
    "            return -x\n",
    "        \n",
    "class MyCell(torch.nn.Module):\n",
    "    def __init__(self, dg):\n",
    "        super(MyCell, self).__init__()\n",
    "        self.dg = dg\n",
    "        self.linear = torch.nn.Linear(4, 4)\n",
    "\n",
    "    def forward(self, x, h):\n",
    "        new_h = torch.tanh(self.dg(self.linear(x)) + h)\n",
    "        return new_h, new_h\n",
    "    \n",
    "my_cell = MyCell(MyDecisionGate())\n",
    "traced_cell = torch.jit.trace(my_cell, (x, h))\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__위에서__\n",
    "\n",
    "- `.code`출력을 보면 `if-else`분기가 어디에도 없는 것을 알 수 있음\n",
    "- 추적 코드는 발생하는 작업을 기록하기 때문에 정확하게 수행하는 ScriptModule을 구성하는 것과 동일하게 수행\n",
    "    - 제어 흐름과 같은 것은 지워짐\n",
    "   \n",
    "- __하지만__Python 소스 코드를 직접 분석하여 TorchScript로 변환하는 스크립트 컴파일러 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:55:28.364212Z",
     "start_time": "2019-10-08T09:55:28.355158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    x: Tensor,\n",
      "    h: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  _0 = self.linear\n",
      "  _1 = _0.weight\n",
      "  _2 = _0.bias\n",
      "  if torch.eq(torch.dim(x), 2):\n",
      "    _3 = torch.__isnot__(_2, None)\n",
      "  else:\n",
      "    _3 = False\n",
      "  if _3:\n",
      "    bias = ops.prim.unchecked_unwrap_optional(_2)\n",
      "    ret = torch.addmm(bias, x, torch.t(_1), beta=1, alpha=1)\n",
      "  else:\n",
      "    output = torch.matmul(x, torch.t(_1))\n",
      "    if torch.__isnot__(_2, None):\n",
      "      bias0 = ops.prim.unchecked_unwrap_optional(_2)\n",
      "      output0 = torch.add_(output, bias0, alpha=1)\n",
      "    else:\n",
      "      output0 = output\n",
      "    ret = output0\n",
      "  _4 = torch.gt(torch.sum(ret, dtype=None), 0)\n",
      "  if bool(_4):\n",
      "    _5 = ret\n",
      "  else:\n",
      "    _5 = torch.neg(ret)\n",
      "  new_h = torch.tanh(torch.add(_5, h, alpha=1))\n",
      "  return (new_h, new_h)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 스크립트 컴파일 통해 MyDecisionGate 변환\n",
    "scripted_gate = torch.jit.script(MyDecisionGate())\n",
    "\n",
    "my_cell = MyCell(scripted_gate)\n",
    "traced_cell = torch.jit.script(my_cell)\n",
    "print(traced_cell.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T09:56:34.623965Z",
     "start_time": "2019-10-08T09:56:34.612025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4201, 0.8930, 0.1284, 0.9095],\n",
       "         [0.4096, 0.7360, 0.6275, 0.6760],\n",
       "         [0.2539, 0.6246, 0.1710, 0.6778]],\n",
       "        grad_fn=<DifferentiableGraphBackward>),\n",
       " tensor([[0.4201, 0.8930, 0.1284, 0.9095],\n",
       "         [0.4096, 0.7360, 0.6275, 0.6760],\n",
       "         [0.2539, 0.6246, 0.1710, 0.6778]],\n",
       "        grad_fn=<DifferentiableGraphBackward>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, h = torch.rand(3, 4), torch.rand(3, 4)\n",
    "traced_cell(x, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T10:05:01.182936Z",
     "start_time": "2019-10-08T10:05:01.178395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7090, 0.0531, 0.7196, 0.8786],\n",
       "        [0.8287, 0.5535, 0.2831, 0.4030],\n",
       "        [0.4868, 0.3671, 0.2124, 0.9849]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스크립팅 및 추적 혼합\n",
    "- 어떤 상황에서는 스크립팅 보다 추적을 사용해야함\n",
    "    - 모듈에는 TorchScript에 표시하지 않으려는 상수 Python값을 기반으로 결정되는 아키텍쳐가 있음\n",
    "    - 이 경우 스크립팅은 추적으로 구성될 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T10:12:30.989832Z",
     "start_time": "2019-10-08T10:12:30.969975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    xs: Tensor) -> Tuple[Tensor, Tensor]:\n",
      "  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
      "  y = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
      "  y0, h0 = y, h\n",
      "  for i in range(torch.size(xs, 0)):\n",
      "    _0 = self.cell\n",
      "    _1 = torch.select(xs, 0, i)\n",
      "    _2 = _0.linear\n",
      "    weight = _2.weight\n",
      "    bias = _2.bias\n",
      "    _3 = torch.addmm(bias, _1, torch.t(weight), beta=1, alpha=1)\n",
      "    _4 = torch.gt(torch.sum(_3, dtype=None), 0)\n",
      "    if bool(_4):\n",
      "      _5 = _3\n",
      "    else:\n",
      "      _5 = torch.neg(_3)\n",
      "    _6 = torch.tanh(torch.add(_5, h0, alpha=1))\n",
      "    y0, h0 = _6, _6\n",
      "  return (y0, h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MyRNNLoop(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyRNNLoop, self).__init__()\n",
    "        self.cell = torch.jit.trace(MyCell(scripted_gate), (x, h))\n",
    "    \n",
    "    def forward(self, xs):\n",
    "        h, y = torch.zeros(3, 4), torch.zeros(3, 4)\n",
    "        for i in range(xs.size(0)):\n",
    "            y, h = self.cell(xs[i], h)\n",
    "        return y, h\n",
    "    \n",
    "rnn_loop = torch.jit.script(MyRNNLoop())\n",
    "print(rnn_loop.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T10:13:27.120687Z",
     "start_time": "2019-10-08T10:13:27.018262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  _0 = self.loop\n",
      "  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
      "  h0 = h\n",
      "  for i in range(torch.size(argument_1, 0)):\n",
      "    _1 = _0.cell\n",
      "    _2 = torch.select(argument_1, 0, i)\n",
      "    _3 = _1.linear\n",
      "    weight = _3.weight\n",
      "    bias = _3.bias\n",
      "    _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1)\n",
      "    _5 = torch.gt(torch.sum(_4, dtype=None), 0)\n",
      "    if bool(_5):\n",
      "      _6 = _4\n",
      "    else:\n",
      "      _6 = torch.neg(_4)\n",
      "    h0 = torch.tanh(torch.add(_6, h0, alpha=1))\n",
      "  return torch.relu(h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class WrapRNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(WrapRNN, self).__init__()\n",
    "    self.loop = torch.jit.script(MyRNNLoop())\n",
    "\n",
    "  def forward(self, xs):\n",
    "    y, h = self.loop(xs)\n",
    "    return torch.relu(y)\n",
    "\n",
    "traced = torch.jit.trace(WrapRNN(), (torch.rand(10, 3, 4)))\n",
    "print(traced.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 및 로드\n",
    "- 아카이브형식으로 디스크에 저장하고 로드하는 API 제공\n",
    "    - 이 형식에는 코드, 매개 변수, 속성 및 디버그 정보가 포함됨\n",
    "    - 아카이브는 완전히 별개의 프로세스로 로드할 수 있는 모델의 독립형 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-08T10:14:25.481796Z",
     "start_time": "2019-10-08T10:14:25.465831Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScriptModule(\n",
      "  (loop): ScriptModule(\n",
      "    (cell): ScriptModule(\n",
      "      (dg): ScriptModule()\n",
      "      (linear): ScriptModule()\n",
      "    )\n",
      "  )\n",
      ")\n",
      "def forward(self,\n",
      "    argument_1: Tensor) -> Tensor:\n",
      "  _0 = self.loop\n",
      "  h = torch.zeros([3, 4], dtype=None, layout=None, device=None, pin_memory=None)\n",
      "  h0 = h\n",
      "  for i in range(torch.size(argument_1, 0)):\n",
      "    _1 = _0.cell\n",
      "    _2 = torch.select(argument_1, 0, i)\n",
      "    _3 = _1.linear\n",
      "    weight = _3.weight\n",
      "    bias = _3.bias\n",
      "    _4 = torch.addmm(bias, _2, torch.t(weight), beta=1, alpha=1)\n",
      "    _5 = torch.gt(torch.sum(_4, dtype=None), 0)\n",
      "    if bool(_5):\n",
      "      _6 = _4\n",
      "    else:\n",
      "      _6 = torch.neg(_4)\n",
      "    h0 = torch.tanh(torch.add(_6, h0, alpha=1))\n",
      "  return torch.relu(h0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traced.save('wrapped_rnn.zip')\n",
    "\n",
    "loaded = torch.jit.load('wrapped_rnn.zip')\n",
    "\n",
    "print(loaded)\n",
    "print(loaded.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytch_env] *",
   "language": "python",
   "name": "conda-env-pytch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
