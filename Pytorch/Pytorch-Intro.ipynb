{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Pytorch 패키치 소개](https://datascienceschool.net/view-notebook/4f3606fd839f4320a4120a56eec1e228/)\n",
    "> GPU 연산 지원하는 딥러닝 프레임워크"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## conda install\n",
    "- https://pytorch.org/get-started/locally/\n",
    "\n",
    "```bash\n",
    "conda install pytorch torchvision cudatoolkit=9.2 -c pytorch -c defaults -c numba/label/dev\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 자료형\n",
    "> Pytorch의 텐서 자료형은 Numpy의 배열과 유사한 자료형\n",
    "\n",
    "- 텐서 자료형을 사용하는 방법도 Numpy와 유사\n",
    "    - 리스트나 Numpy 배열을 텐서로 변환\n",
    "    - 0 또는 1 등의 특정한 값을 가진 텐서를 생성\n",
    "    - 랜덤한 값을 가지는 텐서를 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 배열과 리스트를 텐서 자료형으로 변환\n",
    "- 리스트를 텐서 자료형으로 바꾸려면 `torch.tensor()` 또는 `torch.as_tensor()`, `torch.from_numpy()` 명령 사용\n",
    "    - `torch.tensor()` : 값 복사를 사용하여 새로운 텐서 자료형 인스턴스 생성\n",
    "    - `torch.as_tensor()` : 리스트나 ndarray 객체를 받음, 값 참조를 사용하여 텐서 자료형 뷰를 만듬\n",
    "    - `torch.from_numpy()` : ndarray 객체를 받음, 값 참조를 사용하여 텐서 자료형 뷰를 만듬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "li = np.array([[1,2], [3, 4]])\n",
    "\n",
    "li_tensor = torch.tensor(li)\n",
    "li_as_tensor = torch.as_tensor(li)\n",
    "\n",
    "print(li_tensor)\n",
    "print(li_as_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n",
      "tensor([[1, 2],\n",
      "        [3, 4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "arr_tensor = torch.tensor(arr)\n",
    "arr_as_tensor = torch.from_numpy(arr)\n",
    "arr_from_numpy = torch.from_numpy(arr)\n",
    "\n",
    "print(arr_tensor)\n",
    "print(arr_as_tensor)\n",
    "print(arr_from_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서를 numpy로 바꿀 때는 `torch.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "tensor_to_numpy = arr_tensor.numpy()\n",
    "print(tensor_to_numpy, type(tensor_to_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `torch.as_tensor()`나 `torch.from_numpy()`는 값을 참조하기 때문에 값을 바꾸거나 참조하던 ndarray객체 값이 바뀌면 같이 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 : [[1000    2]\n",
      " [   3    4]]\n",
      "참조하던 tensor : tensor([[1000,    2],\n",
      "        [   3,    4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr_as_tensor[0 ,0] = 1000\n",
    "print(f'원본 : {arr}')\n",
    "print(f'참조하던 tensor : {arr_as_tensor}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원본 : [[1000 2000]\n",
      " [   3    4]]\n",
      "참조하던 tensor : tensor([[1000, 2000],\n",
      "        [   3,    4]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "arr_from_numpy[0, 1] = 2000\n",
    "print(f'원본 : {arr}')\n",
    "print(f'참조하던 tensor : {arr_from_numpy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 랜덤한 값을 가지는 텐서 생성\n",
    "- `torch.rand()` : 0과 1사이 숫자를 균등하게 생성\n",
    "- `torch.randd_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "- `torch.randn()` : 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 생성\n",
    "- `torch.randn_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "- `torch.randint()` : 주어진 범위 내의 점수 균등생성\n",
    "- `torch.randint_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "- `torch.randperm()` : 주어진 범위 내의 정수를 랜덤하게 생성\n",
    "- `torch.manul_seed()` : 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4963, 0.7682, 0.0885, 0.1320, 0.3074])\n",
      "tensor([ 0.5507,  0.2704,  0.6472,  0.2490, -0.3354])\n",
      "tensor([8, 4, 3, 6, 9])\n",
      "tensor([1, 3, 4, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "a = torch.rand(5)\n",
    "b = torch.randn(5)\n",
    "c = torch.randint(10, size=(5,))\n",
    "d = torch.randperm(5)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정한 값으로 초기화를 하지 않는 행렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.empty(3, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특정한 값의 텐서 생성\n",
    "- `torch.arange()` : 주어진 범위 내의 정수를 순서대로 생성\n",
    "- `torch.ones()` : 주어진 사이즈의 1로 이루어진 텐서 생성\n",
    "- `torch.zeros()` : 주어진 사이즈의 0으로 이루어진 텐서 생성\n",
    "- `torch.ones_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "- `torch.zeros_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의\n",
    "- `torch.linspace()` : 시작점과 끝점을 주어진 갯수만큼 균등하게 나눈 간격점을 형벡터로 출력\n",
    "- `torch.logspae()` : 시작점과 끝점을 주어진 갯수만큼 로그간격으로 나눈 간격점을 행벡터로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones((2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0, 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 자료형 변한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int32"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtype 바뀐 값 리턴, 원본은 그대로\n",
    "arr_tensor.type(dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 형상 변환(reshape)\n",
    "- `.view()`사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) torch.Size([4, 3])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]]) torch.Size([3, 4])\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(4, 3)\n",
    "t2 = t1.view(3, 4)\n",
    "t3 = t1.view(12)\n",
    "\n",
    "print(t1, t1.shape)\n",
    "print(t2, t2.shape)\n",
    "print(t3, t3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `squeeze()`나 `unsqueeze()`를 사용해 차원 변환\n",
    "- `squeeze()` : 차원의 원소가 1인 차원을 없애고 값을 return `_`을 붙이면 자체 변수 값 수정\n",
    "- `unsqueeze()` : 인수로 받은 위치에 새로운 차원을 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4 = torch.rand(1,3,3)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5675, 0.8352, 0.2056],\n",
       "        [0.5932, 0.1123, 0.1535],\n",
       "        [0.2417, 0.7262, 0.7011]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.squeeze_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5 = torch.rand(3,3)\n",
    "t5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 복수의 텐서를 결합/분할\n",
    "- `torch.cat()` : 합치는 텐서를 list인자로 주고, 어느 방향으로 결합하는지 dim인자로 줌\n",
    "- `torch.chunk()` : 텐서를 여러개로 나눔\n",
    "- `torch.split()` : 두번째 인자를 기준으로 split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(2, 3)\n",
    "b = torch.zeros(3, 3)\n",
    "\n",
    "torch.cat([a, b], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8579, 0.4486, 0.5139, 0.4569, 0.6012, 0.8179],\n",
      "        [0.9736, 0.8175, 0.9747, 0.4638, 0.0508, 0.2630],\n",
      "        [0.8405, 0.4968, 0.2515, 0.1168, 0.0321, 0.0780]]) torch.Size([3, 6])\n",
      "tensor([[0.8579, 0.4486],\n",
      "        [0.9736, 0.8175],\n",
      "        [0.8405, 0.4968]]) torch.Size([3, 2])\n",
      "tensor([[0.5139, 0.4569],\n",
      "        [0.9747, 0.4638],\n",
      "        [0.2515, 0.1168]]) torch.Size([3, 2])\n",
      "tensor([[0.6012, 0.8179],\n",
      "        [0.0508, 0.2630],\n",
      "        [0.0321, 0.0780]]) torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "c = torch.rand(3, 6)\n",
    "c1, c2, c3 = torch.chunk(c, 3, dim=1)\n",
    "print(c, c.shape)\n",
    "print(c1, c1.shape)\n",
    "print(c2, c2.shape)\n",
    "print(c3, c3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8579, 0.4486, 0.5139],\n",
      "        [0.9736, 0.8175, 0.9747],\n",
      "        [0.8405, 0.4968, 0.2515]]) torch.Size([3, 3])\n",
      "tensor([[0.4569, 0.6012, 0.8179],\n",
      "        [0.4638, 0.0508, 0.2630],\n",
      "        [0.1168, 0.0321, 0.0780]]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "c1, c2 = torch.split(c, 3, dim=1)\n",
    "print(c1, c1.shape)\n",
    "print(c2, c2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서 연산\n",
    "- 연산기호 사용하거나, torch의 함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([0, 1, 2, 3, 4]) z : tensor([1, 2, 3, 4, 5])\n",
      "x + z : tensor([1, 3, 5, 7, 9])\n",
      "tensor([1, 3, 5, 7, 9])\n",
      "tensor([1, 3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 5)\n",
    "z = torch.arange(1, 6)\n",
    "print(f'x : {x} z : {z}')\n",
    "print(f'x + z : {x + z}')\n",
    "print(torch.add(x, z))\n",
    "print(x.add(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 인플레이스 연산\n",
    "- 명령어 뒤에 `_`을 붙이면 자기 자신의 값을 바꾸는 inplace명령이 됨, 연산 결과 반환 동시에 자기 자신의 데이터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : tensor([0, 1, 2, 3, 4])\n",
      "x + z : tensor([1, 3, 5, 7, 9])\n",
      "x : tensor([1, 3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 5)\n",
    "y = torch.arange(1, 6)\n",
    "\n",
    "print(f'x : {x}')\n",
    "print(f'x + z : {x.add_(z)}')\n",
    "print(f'x : {x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1개의 원소를 가진 Tensor를 Python의 Scalar로 만들 때는 `.item()` 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1)\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "scl = torch.tensor(1)\n",
    "print(scl)\n",
    "print(scl.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU 사용\n",
    "- GPU 연산 하기 위해선 텐서를 GPU 연산이 가능한 자료형으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU 연산이 가능한 Tensor 만들기\n",
    "- device 인수에 GPU 디바이스 객체를 입력하거나 문자열을 입력\n",
    "- `torch.device(\"cuda:0\")`로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9722, 0.7910, 0.4690],\n",
       "        [0.3300, 0.3345, 0.3783],\n",
       "        [0.7640, 0.6405, 0.1103]], device='cuda:0')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.rand(3, 3, device=device)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0194, 0.7733, 0.8650],\n",
       "        [0.8097, 0.6666, 0.3653],\n",
       "        [0.3637, 0.5681, 0.2636]], device='cuda:0')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = torch.rand(3, 3, device=\"cuda:0\")\n",
    "ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기존에 있는 Tensor를 GPU 연산이 가능한 자료형으로 바꿀 때는 `.cuda()` 메서드 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2535, -0.0592,  1.1878],\n",
      "        [ 1.2247, -0.8521, -1.1941],\n",
      "        [ 1.1076,  0.6578, -0.0423]])\n",
      "tensor([[-1.2535, -0.0592,  1.1878],\n",
      "        [ 1.2247, -0.8521, -1.1941],\n",
      "        [ 1.1076,  0.6578, -0.0423]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cp = torch.randn(3, 3)\n",
    "print(cp)\n",
    "print(cp.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## autograd\n",
    "- Pytorch에서 핵심적인 기능을 담당하는 하부 패키지\n",
    "- 텐서의 연산에 대해 자동으로 미분값을 구해주는 기능을 함\n",
    "- `requires_grad`인수를 True로 설정하거나 `.requires_grad_(True)`를 실행해 그 텐서에 행해지는 모든 연산에 대한 미분 값 계산\n",
    "- 계산을 멈추고 싶으면 `.detach()`함수를 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8458, 0.1278],\n",
      "        [0.7048, 0.3319]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.0308, grad_fn=<SumBackward0>) <SumBackward0 object at 0x0000020AD906F4E0>\n"
     ]
    }
   ],
   "source": [
    "y = torch.sum(x * 3)\n",
    "# y는 x연산의 결과이므로 미분 함수를 가짐\n",
    "# grad_fn 통해 미분 함수 확인 가능\n",
    "print(y, y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `y.bacward()`함수를 실행하면 x의 미분값이 자동으로 갱신\n",
    "- x의 `grad`속성을 확인하면 미분값이 들어있는 것을 확인할 수 있음\n",
    "- `backward()`함수는 자동으로 미분값을 계산해 `requires_grad`인수가 True로 설정된 변수의 `grad`속성의 값을 갱신\n",
    "- `retain_graph`는 미분을 연산하기 위해서 사용했던 임시 그래프를 유지 할 것인가를 설정\n",
    "    - 동일한 연산에 대해 여러번 미분을 계산하기 위해 유지해줘야 함\n",
    "- 미분값을 그대로 출력받아 사용하고 싶은 경우에는 `torch.autograd.grad()`함수에 출력값과 입력값을 입력하면 미분값을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3., 3.],\n",
       "         [3., 3.]]),)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.grad(y, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상황에 따라 특정 연산에는 미분값을 계산하고 싶지 않을 때\n",
    "- `.detach()`함수 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9976)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_1 = y.detach()\n",
    "torch.sigmoid(y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch를 이용한 선형 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>const</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>501</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>502</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>503</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>504</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>505</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM   ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "501  0.06263  0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527  0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076  0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959  0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741  0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  const  \n",
       "501     21.0  391.99   9.67    1.0  \n",
       "502     21.0  396.90   9.08    1.0  \n",
       "503     21.0  396.90   5.64    1.0  \n",
       "504     21.0  393.45   6.48    1.0  \n",
       "505     21.0  396.90   7.88    1.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['const'] = np.ones(df.shape[0])\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 집 값 : tensor([18.4061], dtype=torch.float64), 실제 집값 : 18.2\n"
     ]
    }
   ],
   "source": [
    "n,m = df.shape\n",
    "\n",
    "X = torch.tensor(df.values)\n",
    "y = torch.tensor(boston.target).view(-1, 1)\n",
    "\n",
    "XT = torch.transpose(X, 0, 1)\n",
    "w = torch.matmul(torch.matmul(torch.inverse(torch.matmul(XT, X)), XT), y)\n",
    "y_pred = torch.matmul(X, w)\n",
    "\n",
    "print(f'예측 집 값 : {y_pred[19]}, 실제 집값 : {boston.target[19]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch를 이용한 퍼셉트론 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "idx = np.in1d(iris.target, [0, 2])\n",
    "x = torch.from_numpy(iris.data[idx, 0:2]).type(torch.float64)\n",
    "y = torch.from_numpy((iris.target[idx] - 1.0)[:, np.newaxis]).type(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.rand((2,1), dtype=torch.float64, requires_grad=True)\n",
    "b = torch.rand((1,1), dtype=torch.float64, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수에 연산,할당을 하고 싶을 때는 변수의 data 속성을 불러와 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.data *= 0.001\n",
    "b.data *= 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD 최적화 수행\n",
    "- `.backward()`를 사용하면 미분값이 계속 누적\n",
    "- 학습한 뒤 가중치를 수정, 수정한 가중치에 대한 미분값으로 다시 학습하기 때문에 가중치를 수정한 뒤에 `.grad_zer_()`함수를 호출하여 변수에 할당된 미분값을 0으로 만들어 줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - loss : 10.255167579625489\n",
      "40 - loss : 2.1622190218221022\n",
      "80 - loss : 0.014426213091849577\n",
      "120 - loss : 0.013727559670846202\n",
      "160 - loss : 0.013029410669724665\n",
      "200 - loss : 0.013308629984686314\n",
      "240 - loss : 0.01306254195886122\n",
      "280 - loss : 0.012365542757194413\n"
     ]
    }
   ],
   "source": [
    "learnig_rate = 0.0001\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    z = (x.mm(w) + b).tanh()\n",
    "    loss_vec = torch.mul(-y, z)\n",
    "    loss = torch.sum(torch.max(torch.cat([torch.zeros_like(loss_vec), loss_vec], dim=-1), dim=-1)[0], dim=-1)\n",
    "    loss.backward()\n",
    "    w.data -= w.grad * learnig_rate\n",
    "    b.data -= b.grad * learnig_rate\n",
    "    \n",
    "    if epoch % 40 == 0:\n",
    "        print(f'{epoch} - loss : {loss.item()}')\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_env] *",
   "language": "python",
   "name": "conda-env-pytorch_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
